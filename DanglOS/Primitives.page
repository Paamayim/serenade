# Primitives

## Scheduling

The scheduler is implemented as a priority queue. Within each priority level, processes are treated in a round-robin fashion in an attempt to prevent any one extremely-high priority process from monopolizing the system.

## Memory Management

Our memory allocator is implemented as a dynamically partitioning linked list. The following pseudo code should provide a high-level overview of the implementation details.

~~~ { .c }
struct memdesc {
    byte *start;
    byte *end;
    memdesc *next;
};

memdesc *memoryHead;
~~~

The $memdesc$ structure has three fields: **start** which marks the starting address of the unpartitioned memory, and **end** which likewise marks the end of allocatable memory. It also contains a field **next** which acts as a stack to previously partitioned blocks of memory which have subsequently been released. The **next** field allows us to retrieve freed memory blocks in constant time, and avoid a linear-time search.

The $memoryHead$ global points to the current head of our linked list, and is assumed to have **start** and **end** already initialized.

~~~ { .c }
void *request_memory_block() {
    void *block = NULL;

    // if a memory block has already been released, give that out
    if (memoryHead->next) {
        memoryHead->next->start;
        memoryHead->next = memoryHead->next->next;
    }

    // if we have unpartitioned memory left, use it
    if (memoryHead->start + MMU_BLOCK_SIZE <= memoryHead->end) {
        block = memoryHead->start;
        memoryHead->start += MMU_BLOCK_SIZE;
    }

    // if one of the earlier allocating schemes was succesful, return it
    if (block) {
        mark_as_allocated(block);
        return block;
    } 

    // otherwise, block until we have memory available
    wait_for_memory();
    return request_memory_block();
}
~~~

Here, $mark\_as\_allocated$ is defined as setting a bit in a bitmask representing the current state of allocated memory blocks. It's purpose, as shown in the following block of code, is to prevent memory from being freed more than once, which could potentially cause self-referential allocation cycles.

$release\_memory\_block$ is relatively straight-forward:

~~~ { .c }
int release_memory_block(void *block) {
    size_t offset = block - memoryHead->start;

    // ensure the block is well-aligned
    if (offset % MMU_BLOCK_SIZE != 0) {
        return not_aligned_error;
    }

    // ensure the block is already allocated
    if (!is_marked_as_allocated(blocked)) {
        return already_freed_error;
    }

    mark_as_free(block);
    block->next = memoryHead->next;
    memoryHead->next = block;

    return success;
}
~~~

## Processor Management

~~~ { .c }
struct pcb {
    proc_state state;
    void *stack_pointer;
    msg_envelope_t *next_message;
};

pcb processes[];
~~~

$pcb$ is a structure which tracks processes information. Among other things, it maintains the current **state** of the process, the **stack_pointer** it had the last time it called $release\_processor$, and a pointer to the head of a linked list of messages in the mailbox, $next\_message$.

$processes$ is an array of all processes currently running on the system.

$release\_processor$'s implementation is relatively unchanged from the sample code. It simply asks the scheduler which process to run next, performs a context-switch to it, and carries along merrily on its way.

~~~ { .c }
void release_processor() {
    push_registers_onto_stack();

    int new_pid = get_next_process_pid();

    pcb *cur_proc = &
    set_stack_pointer(next_proc->stack_pointer);

    pop_registers_off_stack();
}
~~~

## Interprocess Communication

The messaging system is implemented as a per-process queue representing the process' mailbox. To receive a message, we check first if a message has already come in, and if so we dequeue it from the mailbox. If no message currently exists, the process blocks itself and removes itself from the scheduler with the intention of being rescheduled by the message sending code later.

~~~ { .c }
void *receive_message(int *sender) {
    pcb *cur_pcb = &
    msg_envelope_t *msg;

    while (true) {
        msg = cur_pcb->next_message;

        // a message is already in the mailbox
        if (msg) {
            cur_pcb->next_message = msg->next;
            *sender = msg->sender;

            return msg;
        }

        // wait for a message to arrive
        pcb->state = BLOCKED_ON_MESSAGE;
        remove_from_scheduler(current_pid);
        release_processor();
    }
}
~~~

Message sending is likewise very straight forward. Before sending the message, its routing information is first filled in, and then it is appended to the recipient process' mailbox. If the recipient process is currently *BLOCKED_ON_MESSAGE*, it is rescheduled. Finally, if the destination process has a higher priority than the current process, the current process relinquishes its time share.

~~~ { .c }
void send_message(msg_envelope_t *msg, int pid) {
    msg->sender = current_pid;
    msg->recipient = pid;

    pcb *dest_proc = &
    if (pcb->state == BLOCKED_ON_MESSAGE) {
        pcb->state = READY;
        add_to_scheduler(pid);
    }

    add_message_to_list(pcb->next_message, msg);

    if (dest_proc->priority > cur_proc->priority) {
        release_processor();
    }    
}
~~~

## Timing Services

I DONT KNOW WAT IM DOIN. Jacob, would you mind filling this in?

## Process Priority

To facilitate changing priorities of processes, we store each process' priority in the $pcb$. This allows for constant-time priority lookups. Because the scheduler is implemented as a series of queues each with a given priority, changing priority is as simple as removing the process from one location in the priority queue and adding it to another location. We consider the implementation self-evident enough that it need not be described any further here.